<!DOCTYPE html>
<html>

<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-62655793-4"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());

        gtag('config', 'UA-62655793-4');
    </script>

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <script type="text/javascript" src="../main.js" charset="utf-8"></script>
    <link href="https://fonts.googleapis.com/css?family=Literata&display=swap" rel="stylesheet">

    <title>Kubernetes Servcie</title>

    <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
    <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
    <link rel="stylesheet" href="../style.css">

</head>

<body>
    <div class="nav-home">
        <a class="btn-primary" href="../index.html">Home</a>
    </div>
    <div class="vscode-light note-container">

        <h1 id="services">Services</h1>
        <ul>
            <li>Services groups pods to provide common access points from the external world to the containerized
                applications.</li>
            <li>kube-proxy daemon runs on each worker node to provide access to services.</li>
            <li>To access the application, a user/client needs to connect to the Pods.</li>
            <li>Pods are ephemeral in nature, resource like IP address allocated to it cannot be static.</li>
            <li>Pods could be terminated abruptly or be rescheduled based on existing requirements.</li>
            <li>Example: user/client is connected to a Pod using its IP address.<br>
                <img src="https://i.imgur.com/eGUcrBq.png" alt="Imgur"><br>
                Unexpecctly, the pod to which the user/client is connected is terminated, and a new Pod is created by
                the controller. The new Pod will have a new IP address, which will not be known automatically to the
                user/client of the earlier Pod.<br>
                <img src="https://i.imgur.com/rSdEKh0.png" alt="Imgur"><br>
                To overcome this situation, k8s provides a higher-level abstraction called <a
                    href="https://kubernetes.io/docs/concepts/services-networking/service/">Service</a>, which logically
                groups Pods andd defines a policy to access them.<br>
                Grouping is achieved via <strong>Labels</strong> <strong>Selectors</strong>.</li>
            <li>Example: <strong>app</strong> is the Label key, <strong>frontend</strong> and <strong>db</strong> are
                Label values for different Pods.<br>
                <img src="https://i.imgur.com/rRNgj1l.png" alt="Imgur"><br>
                Using the selectors <strong>app==frontend</strong> and <strong>app==db</strong>, we groups pods into two
                logical set: one with 3 Pods, and one with a single Pod.<br>
                we assign a name to the logical grouping, referred to as a <strong>Service</strong>. In our example, we
                create two Services, <strong>frontend-svc</strong>, and <strong>db-svc</strong>, and they have the
                <strong>app==frontend</strong> and the** app==db** Selectors, respectively<br>
                <img src="https://i.imgur.com/7wyLvCQ.png" alt="Imgur"></li>
            <li>Services can expose:
                <ul>
                    <li>single Pods</li>
                    <li>ReplicaSets</li>
                    <li>Deployments</li>
                    <li>DaemonSets</li>
                    <li>StatefulSets.</li>
                </ul>
            </li>
        </ul>
        <h2 id="service-object">Service Object</h2>
        <ul>
            <li>Example
                <pre><code class="language-YAML"><div><span class="hljs-attr">kind:</span> <span class="hljs-string">Service</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
<span class="hljs-attr">metadata:</span>
<span class="hljs-attr">name:</span> <span class="hljs-string">frontend-svc</span>
<span class="hljs-attr">spec:</span>
<span class="hljs-attr">selector:</span>
<span class="hljs-attr">    app:</span> <span class="hljs-string">frontend</span>
<span class="hljs-attr">ports:</span>
<span class="hljs-attr">- protocol:</span> <span class="hljs-string">TCP</span>
<span class="hljs-attr">    port:</span> <span class="hljs-number">80</span>
<span class="hljs-attr">    targetPort:</span> <span class="hljs-number">5000</span>
</div></code></pre>
                <ul>
                    <li>We create a <strong>frontend-svc</strong> Service</li>
                    <li>It selects all the Pods that have the Label key=<strong>app</strong> set to
                        value=<strong>frontend</strong></li>
                    <li>By default, each Service <strong>receives an IP address</strong> routable only inside the
                        cluster, known as <strong>ClusterIP</strong><br>
                        <img src="https://i.imgur.com/7wyLvCQ.png" alt="Imgur"></li>
                    <li>in the example, we have 172.17.0.4 and 172.17.0.5 as ClusterIPs assigned to our frontend-svc and
                        db-svc Servcies respectively.</li>
                    <li>The user/client now connects to a Servcie via its ClusterIP.</li>
                    <li>ClusterIP forwards traffic to one of the Pods attached to it.</li>
                    <li>A Service provides load <strong>balancing by default</strong> while selecting the Pods for
                        traffic forwarding.</li>
                    <li>while the Service forwards traffic to Pods, we can select the <strong>targetPort</strong> on the
                        Pod which receives the traffic.</li>
                    <li>in our example, the <strong>frontend-svc</strong> receives on <strong>port 80</strong>, then
                        forwards these request to one fo the attached Pods on the <strong>targetPort 5000</strong>.</li>
                    <li>if the <strong>targetPort</strong> is <strong>not defined</strong> explicitly, then traffic will
                        be forwarded to Pods on the port on which the Service receives traffic.</li>
                    <li>A logical set of Pod's <strong>IP address</strong>, along with the <strong>targetPort</strong>
                        is referred as a <strong>Service endpoint</strong></li>
                    <li>In our example, the frontend-svc Service has 3 endpoints:
                        <ul>
                            <li>10.0.1.3:5000</li>
                            <li>10.0.1.4:5000</li>
                            <li>10.0.1.5:5000<br>
                                Endpoints are created and <strong>managed automatically</strong> by the Servcie, not by
                                k8s cluster administrator.</li>
                        </ul>
                    </li>
                </ul>
            </li>
        </ul>
        <h2 id="kube-proxy">Kube-Proxy</h2>
        <ul>
            <li>
                <p>All worker nodes run a daemon called <a
                        href="https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies">kue-proxy</a>.
                </p>
            </li>
            <li>
                <p>It watches the API server on the master node for the addition and removal of Services and endpoints.
                </p>
            </li>
            <li>
                <p>Example in iptables proxy mode:<br>
                    <img src="https://i.imgur.com/1lko9So.png" alt="Imgur"><br>
                    <em>Kube-proxy, Services and Endponts (user DNS service discovery explained below.)</em></p>
                <ul>
                    <li>By default, kube-proxy in iptables mode chooses a backend at random.</li>
                    <li>for each new Service, on each node, kube-proxy configures <strong>iptables</strong> rules to
                        capture the traffic for its ClusterIP and forwards it to one of the Service's endpoints.</li>
                    <li>Any node can receive the external traffic and then route it internally in the cluster based on
                        the <strong>iptables</strong> rules.</li>
                    <li>When the Service is removed, <strong>kube-proxy</strong> removes the corresponding
                        <strong>iptables</strong> rules on all nodes as well.</li>
                </ul>
            </li>
        </ul>
        <h2 id="service-discovery">Service Discovery.</h2>
        <ul>
            <li>Servcie are the primary mode of communication in K8s.</li>
            <li>We need a way to discover them at runtime.</li>
            <li>K8s supports two methods for discovering Services.
                <ul>
                    <li><strong>Environment Varialbes</strong></li>
                    <li><strong>DNS</strong></li>
                </ul>
            </li>
        </ul>
        <h3 id="environment-variables">Environment Variables</h3>
        <ul>
            <li>As soon as the Pod starts on any worker node, the kubelet daemon running on that node adds a set of
                environment variable in the Pod for all active Services.</li>
            <li>Example:
                <ul>
                    <li>if we have an active Service called redis-master, which exposes port 6379, and its ClusterIP is
                        172.17.0.6, then on a newly created Pod, we can see the following environment variables.</li>
                </ul>
                <pre><code class="language-yaml"><div><span class="hljs-string">REDIS_MASTER_SERVICE_HOST=172.17.0.6</span>
<span class="hljs-string">REDIS_MASTER_SERVICE_PORT=6379</span>
<span class="hljs-string">REDIS_MASTER_PORT=tcp://172.17.0.6:6379</span>
<span class="hljs-string">REDIS_MASTER_PORT_6379_TCP=tcp://172.17.0.6:6379</span>
<span class="hljs-string">REDIS_MASTER_PORT_6379_TCP_PROTO=tcp</span>
<span class="hljs-string">REDIS_MASTER_PORT_6379_TCP_PORT=6379</span>
<span class="hljs-string">REDIS_MASTER_PORT_6379_TCP_ADDR=172.17.0.6</span>
</div></code></pre>
                <ul>
                    <li>With this solution, we need to be careful while ordering our Services.</li>
                    <li>Pod <strong>will not</strong> have the environment variables set for Services which are
                        <strong>created after</strong> thye Pods are created.</li>
                </ul>
            </li>
        </ul>
        <h3 id="dns">DNS</h3>
        <ul>
            <li>K8s has an <a href="https://kubernetes.io/docs/concepts/cluster-administration/addons/">add-on</a> for
                <a href="https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/dns">DNS</a></li>
            <li>DNS record for each Service format is <strong>my-svc.my-namespace.svc.cluster.local</strong>.</li>
            <li>Service within the same Namespace find other Services just by their name.</li>
            <li>If we add a Service <strong>redis-master</strong> in <strong>my-ns</strong> Namespace, all Pods in the
                same Namespace lookup the Service just by its name, <strong>redis-master</strong>.</li>
            <li>Pods from other Namespace lookup the same Service by adding the respective Namespce as a suffix, such as
                <strong>redis-master.my-ns</strong>.</li>
            <li>DNS is the most common and highly recommended solution.</li>
        </ul>
        <h2 id="service-type">Service Type.</h2>
        <ul>
            <li>We can choose access scope for Service.
                <ul>
                    <li>Is only accessible within the cluster.</li>
                    <li>Is accessible from within the cluster and the external world.</li>
                    <li>Maps to an entity which resides either inside or outside the cluster.</li>
                </ul>
            </li>
            <li>Access scope is decided by ServiceType, which can be configure when creating the Service.</li>
        </ul>
        <h3 id="clusterip"><strong>ClusterIP</strong></h3>
        <ul>
            <li>is the default ServiceType.</li>
            <li>A Service receives a VirtualIP address, known as its ClusterIP.</li>
            <li>This Virutal IP address is used for communicating with the Service and is accessible only within the
                cluster.</li>
        </ul>
        <h3 id="nodeport"><strong>NodePort</strong></h3>
        <ul>
            <li>in addition to a ClusterIP, a high-port, dynamically picked form the defualt range <strong>30000 -
                    32767</strong> , is mapped to the respective Service, from <strong>all the worker nodes</strong>.
            </li>
            <li>Example: if the mapped NodePort is 32233 for the service <strong>frontend-svc</strong>, then, if we
                connect to any worker node on port 32233, the node would redirect all the traffic to the assigned
                ClusterIP - <strong>172.17.0.4</strong>.</li>
            <li>if we prefer a specific high-port number instead, then we can assign that high-port number to the
                NodePort fro mthe default range.<br>
                <img src="https://i.imgur.com/7fkIb0r.png" alt="Imgur"><br>
                <em><strong>NodePort</strong></em></li>
            <li>The <strong>NodePort</strong> ServiceType is useful when we want to make our Services accessible from
                the external world.</li>
            <li>The end-user connects to any worker node on the specified high-port, which proxy the request internally
                to the ClusterIP of the Service, then the reqeust is forwarded to the applications running inside the
                cluter.</li>
            <li>To access multiple applications from the external world, administrators can configure a reverse proxy -
                <strong>an ingress</strong>, and define rules that target Services within the cluster.</li>
        </ul>
        <h3 id="loadbalancer"><strong>LoadBalancer</strong></h3>
        <ul>
            <li><strong>NodePort</strong> and <strong>ClusterIP</strong> are <strong>automatically created</strong>, and
                the external load balancer will route to them.</li>
            <li>The Service is exposed at a static port on each worker node.</li>
            <li>The Service is exposed extrnally using the underlying colud provider's load balancer feature.<br>
                <img src="https://i.imgur.com/rYdbisn.png" alt="Imgur"><br>
                <strong>LoadBalancer</strong></li>
            <li>The LoadBalancer ServiceType will only work if the udnerlying infrastructure supports the automatic
                creation of Load Balancers and have the respective support in K8s, e.g Google Could Platforms and AWS.
            </li>
            <li>If infrastructure doesn't support the feature, the LoadBalancer IP address field is not populated, and
                the Service will work the same way as a NodePort type Service.</li>
        </ul>
        <h3 id="externalip"><strong>ExternalIP</strong></h3>
        <ul>
            <li>A Service can be mapped to na ExternalIP address if it can route to one or more of the worker nodes.
            </li>
            <li>Traffic that is ingressed into the cluster with the ExternalIP (as destination IP) on the Service port,
                gets routed to one of the Service endpoints.</li>
            <li>This type of servcie requires an external could provider such as Google Cloud Platform or AWS.<br>
                <img src="https://i.imgur.com/LUxow5w.png" alt="Imgur"></li>
            <li>ExternalIPs are <strong>not managed by K8s</strong>.</li>
            <li>The cluster administator has to configure the routing which maps the ExternalIP address to one of the
                nodes.</li>
        </ul>
        <h3 id="externalname"><strong>ExternalName</strong></h3>
        <ul>
            <li>External Name is a special ServiceType, that has no Selectors and doesn't define any endpoints.</li>
            <li>When accessed within the cluster, it returns a <strong>CNAME</strong> record of an externally configured
                Service.</li>
            <li>The primary use case of this ServiceType is to make externally configured Services like <strong><a
                        href="http://my-database.example.com">my-database.example.com</a></strong> available to
                applicaitons inside the cluster.</li>
            <li>If the externally defined Service resides within the same Namesapce, using just the name
                <strong>my-database</strong> would make it available to other applications as Services within that same
                Namespace.</li>
        </ul>


    </div>
</body>
<footer>
    <div class="nav-home--footer">
        <a class="btn-primary" href="../index.html">Home</a>
    </div>
</footer>


</html>